{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c513d4c5-0cf1-4682-9307-3399514a47d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "# import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e548b4d5-84a3-406d-949a-e44f6882b62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "\n",
    "# separate data into predictor and target\n",
    "concrete_data_columns = concrete_data.columns\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']]\n",
    "target = concrete_data['Strength']\n",
    "\n",
    "# number of predictors for input into during model creation\n",
    "n_cols = predictors.shape[1] \n",
    "\n",
    "\n",
    "# model creation for parts A-C\n",
    "def regression_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "# model creation for part D\n",
    "def regression_model_partD():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "# create a regression model for each part of assignment\n",
    "modelA = regression_model()\n",
    "modelB = regression_model()\n",
    "modelC = regression_model()\n",
    "modelD = regression_model_partD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13986609-a5ab-4ea6-af64-bb07393fba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART A\n",
    "X_trainA, X_testA, y_trainA, y_testA = train_test_split(predictors, target, test_size=0.3, random_state=11)\n",
    "\n",
    "mse_partA = []\n",
    "for n in range(50):\n",
    "    modelA.fit(predictors, target, epochs=50, verbose=0)\n",
    "    y_predA = modelA.predict(X_testA)\n",
    "    mse_partA.append(metrics.mean_squared_error(y_testA, y_predA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aac0d767-6097-4af9-bb94-0f7e6ed75757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART B - normalized version\n",
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "#target_norm = (target - target.mean()) / target.std()\n",
    "\n",
    "X_trainB, X_testB, y_trainB, y_testB = train_test_split(predictors_norm, target, test_size=0.3, random_state=11)\n",
    "\n",
    "mse_partB = []\n",
    "for n in range(50):\n",
    "    modelB.fit(predictors_norm, target, epochs=50, verbose=0)\n",
    "    y_predB = modelB.predict(X_testB)\n",
    "    mse_partB.append(metrics.mean_squared_error(y_testB, y_predB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79845144-aded-4709-89f7-226c45b363ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART C - 100 epochs\n",
    "X_trainC, X_testC, y_trainC, y_testC = train_test_split(predictors_norm, target, test_size=0.3, random_state=11)\n",
    "\n",
    "mse_partC = []\n",
    "for n in range(50):\n",
    "    modelC.fit(predictors_norm, target, epochs=100, verbose=0)\n",
    "    y_predC = modelC.predict(X_testC)\n",
    "    mse_partC.append(metrics.mean_squared_error(y_testC, y_predC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0d433b8-2ede-47ca-af84-ab0eda91a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part D - increased # of hidden layers\n",
    "X_trainD, X_testD, y_trainD, y_testD = train_test_split(predictors_norm, target, test_size=0.3, random_state=11)\n",
    "\n",
    "mse_partD = []\n",
    "for n in range(50):\n",
    "    modelD.fit(predictors_norm, target, epochs=50, verbose=0)\n",
    "    y_predD = modelD.predict(X_testD)\n",
    "    mse_partD.append(metrics.mean_squared_error(y_testD, y_predD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83f3681b-99fb-4626-87ff-a30fab51820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_partA = sum(mse_partA)/len(mse_partA)\n",
    "avg_partB = sum(mse_partB)/len(mse_partB)\n",
    "avg_partC = sum(mse_partC)/len(mse_partC)\n",
    "avg_partD = sum(mse_partD)/len(mse_partD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42a2303e-f18b-4322-bf61-f7fcaf864a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of MSE part A: 107.37454209810647\n",
      "Average of MSE part B: 49.93508258246155\n",
      "Average of MSE part C: 47.051987140761156\n",
      "Average of MSE part D: 20.778669365238034\n"
     ]
    }
   ],
   "source": [
    "print(f'Average of MSE part A: {avg_partA}')\n",
    "print(f'Average of MSE part B: {avg_partB}')\n",
    "print(f'Average of MSE part C: {avg_partC}')\n",
    "print(f'Average of MSE part D: {avg_partD}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f38d8f5-85a5-4586-8f61-f6ee7270c821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[287.98714722762276,\n",
       " 165.38267752145143,\n",
       " 126.42225856068617,\n",
       " 107.93586772632086,\n",
       " 101.6679698342388,\n",
       " 100.89032411296888,\n",
       " 107.40240967387511,\n",
       " 99.88169346475053,\n",
       " 101.96311063314985,\n",
       " 102.44053675594998,\n",
       " 99.32773796795327,\n",
       " 101.73690490317703,\n",
       " 102.98899655613748,\n",
       " 99.69947912656593,\n",
       " 104.45694354112065,\n",
       " 102.6518329594178,\n",
       " 109.67149782510474,\n",
       " 102.38453241089728,\n",
       " 99.42988501465155,\n",
       " 99.5663576179568,\n",
       " 99.64116355536599,\n",
       " 99.56573416861089,\n",
       " 103.84922242391094,\n",
       " 103.0534835571832,\n",
       " 100.25579072519842,\n",
       " 101.69475482272564,\n",
       " 99.78004588237464,\n",
       " 99.41263227223794,\n",
       " 99.47957842259022,\n",
       " 101.04773883612337,\n",
       " 100.96584693343935,\n",
       " 99.31564366592993,\n",
       " 100.04272280128792,\n",
       " 99.48520738996568,\n",
       " 102.05875424468897,\n",
       " 120.18195646359146,\n",
       " 99.28318035872711,\n",
       " 99.93103273284666,\n",
       " 99.7046321093662,\n",
       " 107.71674225702739,\n",
       " 99.13732330239489,\n",
       " 99.2047211841852,\n",
       " 104.31559197190556,\n",
       " 99.28767077033797,\n",
       " 99.82065532259459,\n",
       " 99.51114269868573,\n",
       " 99.16003033863177,\n",
       " 100.02932658461201,\n",
       " 104.33987324693304,\n",
       " 103.5667424278532]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_partA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d83ce6-cda6-4561-8500-2644dfc4298f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
